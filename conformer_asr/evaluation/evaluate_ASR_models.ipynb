{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-04-04 09:39:20 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from nemo.utils import logging\n",
    "import torch\n",
    "import contextlib\n",
    "import nemo\n",
    "import editdistance\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55188 /home/khoatlv/Conformer_ASR/scripts/evaluation/all_data_manifest.json\n"
     ]
    }
   ],
   "source": [
    "test_manifest = \"/home/khoatlv/manifests/test_manifest_processed.json\"\n",
    "train_manifest = \"/home/khoatlv/manifests/train_manifest_processed.json\"\n",
    "all_data_manifest = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/all_data_manifest.json\"\n",
    "\n",
    "# pickle data\n",
    "probs_cache_file = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/eval_asr_model/probs_cache_file\"\n",
    "conformer_transcribe_log = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/eval_asr_model/conformer_log.json\"\n",
    "\n",
    "os.system(f\"cat {test_manifest} {train_manifest} > {all_data_manifest}\")\n",
    "os.system(f\"wc -l {all_data_manifest}\")\n",
    "\n",
    "use_amp = True\n",
    "acoustic_batch_size = 16\n",
    "beam_width = 200\n",
    "alpha=2\n",
    "beta=2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e = np.exp(x - np.max(x))\n",
    "    return e / e.sum(axis=-1).reshape([x.shape[0], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Conformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-04 09:39:23 mixins:146] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-04-04 09:39:23 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /home/nhan/NovaIntechs/data/ASR_Data/manifests/train_manifest_processed.json\n",
      "    sample_rate: 16000\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    shuffle: true\n",
      "    batch_size: 32\n",
      "    pin_memory: true\n",
      "    trim_silence: true\n",
      "    use_start_end_token: true\n",
      "    normalize_transcripts: false\n",
      "    num_workers: 16\n",
      "    \n",
      "[NeMo W 2022-04-04 09:39:23 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /home/nhan/NovaIntechs/data/ASR_Data/manifests/test_manifest_processed.json\n",
      "    sample_rate: 16000\n",
      "    pin_memory: true\n",
      "    shuffle: false\n",
      "    batch_size: 8\n",
      "    trim_silence: true\n",
      "    use_start_end_token: true\n",
      "    normalize_transcripts: false\n",
      "    num_workers: 16\n",
      "    \n",
      "[NeMo W 2022-04-04 09:39:23 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: /home/nhan/NovaIntechs/data/ASR_Data/manifests/test_manifest_processed.json\n",
      "    sample_rate: 16000\n",
      "    pin_memory: true\n",
      "    shuffle: false\n",
      "    batch_size: 8\n",
      "    trim_silence: true\n",
      "    use_start_end_token: true\n",
      "    normalize_transcripts: false\n",
      "    num_workers: 16\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-04 09:39:23 features:255] PADDING: 0\n",
      "[NeMo I 2022-04-04 09:39:23 features:272] STFT using torch\n",
      "[NeMo I 2022-04-04 09:39:29 save_restore_connector:157] Model EncDecCTCModelBPE was successfully restored from /home/khoatlv/Conformer_ASR/models/conformer/Conformer_small_epoch=98.nemo.\n"
     ]
    }
   ],
   "source": [
    "lm_path = \"/home/khoatlv/Conformer_ASR/n_gram_lm/n_gram_lm_model/6-conformer-small-gram_trained.bin\"\n",
    "asr_model_path = \"/home/khoatlv/Conformer_ASR/models/conformer/Conformer_small_epoch=98.nemo\"\n",
    "\n",
    "# Restore ASR Model\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.restore_from(\n",
    "    restore_path=asr_model_path,\n",
    "    map_location='cuda'    \n",
    ")\n",
    "\n",
    "# Restore Beam Search N-LM\n",
    "TOKEN_OFFSET = 100\n",
    "vocab = asr_model.decoder.vocabulary\n",
    "vocab = [chr(idx + TOKEN_OFFSET) for idx in range(len(vocab))]\n",
    "ids_to_text_func = asr_model.tokenizer.ids_to_text\n",
    "\n",
    "beam_search_lm = nemo_asr.modules.BeamSearchDecoderWithLM(\n",
    "    vocab=list(vocab),\n",
    "    beam_width=beam_width,\n",
    "    alpha=alpha, \n",
    "    beta=beta,\n",
    "    lm_path=lm_path,\n",
    "    num_cpus=max(os.cpu_count(), 1),\n",
    "    input_tensor=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c3af5d84c048ef919bbe21619359be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Manifest /home/khoatlv/Conformer_ASR/scripts/evaluation/all_data_manifest.json ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-04 09:40:15 987078218:13] Found a pickle file of probabilities at '/home/khoatlv/Conformer_ASR/scripts/evaluation/eval_asr_model/probs_cache_file'.\n",
      "[NeMo I 2022-04-04 09:40:15 987078218:14] Loading the cached pickle file of probabilities from '/home/khoatlv/Conformer_ASR/scripts/evaluation/eval_asr_model/probs_cache_file' ...\n",
      "[NeMo I 2022-04-04 09:40:21 987078218:43] ==============================Starting the beam search decoding===============================\n",
      "[NeMo I 2022-04-04 09:40:21 987078218:45] It may take some time...\n",
      "[NeMo I 2022-04-04 09:40:21 987078218:46] ==============================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60fedb6edee428b85134f7d9ac42b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Beam search decoding with width=200, alpha=2, beta=2.5:   0%|                                  | 0/3450 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: em liền gọi to. pred_text: em liền gọi to. wer: 0.0%\n",
      "target: ở cái nơi rừng thiêng nước độc này. pred_text: ở nơi dừng vui huy động này. wer: 0.62%\n",
      "target: anh nấy cũng khoe rằng ảnh của mình hơn. pred_text: anh ấy cũng khoe rằng ảnh của mình hơn. wer: 0.11%\n",
      "target: nhuộm ánh nắng tà qua mái tóc. pred_text: ánh nắng tang bên ngoài tóc. wer: 0.57%\n",
      "target: không không không sao đâu. pred_text: không song không sao đâu. wer: 0.2%\n",
      "target: nó cứ nhìn chằm chằm vào đó. pred_text: nó cứ nhìn chằm chằm vào đó. wer: 0.0%\n",
      "target: nên mỗi lần đi đâu về muộn một chút. pred_text: nên mỗi lần đi đâu về muộn một chút. wer: 0.0%\n",
      "target: những câu chuyện hay những bức ảnh được chúng tôi khoe lại. pred_text: những câu chuyện hay những bức ảnh được chúng tôi khoe lại. wer: 0.0%\n",
      "target: cũng vừa mới ngồi thôi nước còn chưa uống hết một nửa đây này. pred_text: cũng vừa mới ngồi thôi nước còn chưa uống hết một nửa đây này. wer: 0.0%\n",
      "target: vậy thì tại sao không giúp mình chiếm được tình cảm của quân. pred_text: vậy thì tại sao không giúp mình chiếm được tình cảm của mình. wer: 0.08%\n",
      "target: có hay chăng là con bé đó gây ra không. pred_text: có hay chăng là con bé đó gây ra không. wer: 0.0%\n",
      "target: từ giọng cô dịu hiền. pred_text: vì già cô dịu hiện. wer: 0.6%\n",
      "target: lẽ ra thì chúng tôi không nên nhắc lại. pred_text: lẽ ra thì chúng tôi không nên nhắc lại. wer: 0.0%\n",
      "target: dường như chậm lại. pred_text: dương nghĩa trọng lạnh. wer: 1.0%\n",
      "target: vẫn là trinh. pred_text: vẫn loài khinh. wer: 0.67%\n",
      "target: bà tâm đau khổ nhìn con rồi lắc đầu. pred_text: bà tâm đau khổ nhìn con rồi lắc đầu. wer: 0.0%\n",
      "[NeMo I 2022-04-04 09:40:22 987078218:87] WER with beam search decoding and N-gram model = 0.16\n"
     ]
    }
   ],
   "source": [
    "def eval_comformer():\n",
    "    # Load manifest data and extract audio_path, target text\n",
    "    target_transcripts = []\n",
    "    with open(all_data_manifest, 'r') as manifest_file:\n",
    "        audio_file_paths = []\n",
    "        for line in tqdm(manifest_file, desc=f\"Reading Manifest {all_data_manifest} ...\", ncols=120):\n",
    "            data = json.loads(line)\n",
    "            target_transcripts.append(data['text'])\n",
    "            audio_file_paths.append(data['audio_filepath'])\n",
    "    \n",
    "    # Load audio wav and transribe\n",
    "    if probs_cache_file and os.path.exists(probs_cache_file):\n",
    "        logging.info(f\"Found a pickle file of probabilities at '{probs_cache_file}'.\")\n",
    "        logging.info(f\"Loading the cached pickle file of probabilities from '{probs_cache_file}' ...\")\n",
    "        with open(probs_cache_file, 'rb') as probs_file:\n",
    "            all_probs = pickle.load(probs_file)\n",
    "\n",
    "        if len(all_probs) != len(audio_file_paths):\n",
    "            raise ValueError(\n",
    "                f\"The number of samples in the probabilities file '{probs_cache_file}' does not \"\n",
    "                f\"match the manifest file. You may need to delete the probabilities cached file.\"\n",
    "            )\n",
    "    else:\n",
    "        if use_amp:\n",
    "            if torch.cuda.is_available() and hasattr(torch.cuda, 'amp') and hasattr(torch.cuda.amp, 'autocast'):\n",
    "                logging.info(\"AMP is enabled!\\n\")\n",
    "                autocast = torch.cuda.amp.autocast\n",
    "        else:\n",
    "\n",
    "            @contextlib.contextmanager\n",
    "            def autocast():\n",
    "                yield\n",
    "\n",
    "        with autocast():\n",
    "            with torch.no_grad():\n",
    "                all_logits = asr_model.transcribe(audio_file_paths, batch_size=acoustic_batch_size, logprobs=True)\n",
    "        all_probs = [softmax(logits) for logits in all_logits]\n",
    "        if probs_cache_file:\n",
    "            logging.info(f\"Writing pickle files of probabilities at '{probs_cache_file}'...\")\n",
    "            with open(probs_cache_file, 'wb') as f_dump:\n",
    "                pickle.dump(all_probs, f_dump)\n",
    "                \n",
    "    logging.info(f\"==============================Starting the beam search decoding===============================\")\n",
    "    # logging.info(f\"Grid search size: {len([]])}\")\n",
    "    logging.info(f\"It may take some time...\")\n",
    "    logging.info(f\"==============================================================================================\")\n",
    "    \n",
    "    wer_dist_count = 0\n",
    "    words_count = 0\n",
    "    sample_idx = 0\n",
    "    \n",
    "    if conformer_transcribe_log:\n",
    "        out_file = open(conformer_transcribe_log, 'w', encoding='UTF8', newline='')\n",
    "        writer = csv.writer(out_file)\n",
    "        headers = [\"audio_filepath\", \"pred_text\", \"reference\", \"wer\"]\n",
    "        writer.writerow(headers)\n",
    "    \n",
    "    it = tqdm(\n",
    "        range(int(np.ceil(len(all_probs) / acoustic_batch_size))),\n",
    "        desc=f\"Beam search decoding with width={beam_width}, alpha={alpha}, beta={beta}\",\n",
    "        ncols=120,\n",
    "    )\n",
    "    for batch_idx in it:\n",
    "        # disabling type checking\n",
    "        with nemo.core.typecheck.disable_checks():\n",
    "            probs_batch = all_probs[batch_idx * acoustic_batch_size : (batch_idx + 1) * acoustic_batch_size]\n",
    "            beams_batch = beam_search_lm.forward(log_probs=probs_batch, log_probs_length=None,)\n",
    "        \n",
    "        for beams_idx, beams in enumerate(beams_batch):\n",
    "            target = target_transcripts[sample_idx + beams_idx]\n",
    "            target_split_w = target.split()\n",
    "            words_count += len(target_split_w)\n",
    "            \n",
    "            # For BPE encodings, need to shift by TOKEN_OFFSET to retrieve the original sub-word ids\n",
    "            pred_text = ids_to_text_func([ord(c) - TOKEN_OFFSET for c in beams[0][1]])\n",
    "            pred_split_w = pred_text.split()\n",
    "            wer_dist = editdistance.eval(target_split_w, pred_split_w)\n",
    "            wer_dist_count += wer_dist\n",
    "            \n",
    "            wer = round(float(\"{:.2}\".format(wer_dist / len(target_split_w))), 2)\n",
    "            print(f\"target: {target}. pred_text: {pred_text}. wer: {wer}%\")\n",
    "            \n",
    "            audio_path = audio_file_paths[sample_idx + beams_idx]\n",
    "            if round(float(wer), 2) > 0.5: writer.writerow([audio_path, pred_text, target, wer])\n",
    "        # break\n",
    "        sample_idx += len(probs_batch)\n",
    "    \n",
    "    logging.info(\n",
    "        'WER with beam search decoding and N-gram model = {:.2}'.format(wer_dist_count / words_count))\n",
    "    \n",
    "    if conformer_transcribe_log:\n",
    "        out_file.close()\n",
    "eval_comformer()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
