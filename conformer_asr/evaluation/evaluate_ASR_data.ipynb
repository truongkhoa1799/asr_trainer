{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from pyctcdecode import Alphabet, BeamSearchDecoderCTC, LanguageModel\n",
    "import kenlm\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from joblib.parallel import Parallel\n",
    "import joblib\n",
    "import soundfile as sf\n",
    "\n",
    "import soundfile as sf\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9141 /home/khoatlv/Conformer_ASR/scripts/evaluation/manifests/data_collected_eval_manifests.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifests_dir = \"/home/khoatlv/manifests\"\n",
    "test_manifest_processed_processed = os.path.join(manifests_dir, \"test_manifest_processed.json\")\n",
    "train_manifest_processed_processed = os.path.join(manifests_dir, \"train_manifest_processed.json\")\n",
    "\n",
    "manifests_processed_all = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/manifests/data_collected_eval_manifests.json\"\n",
    "\n",
    "if os.path.exists(manifests_processed_all): os.remove(manifests_processed_all)\n",
    "os.system(\"cat {test_manifest_processed_processed} {train_manifest_processed_processed} > {manifests_processed_all}\".format(\n",
    "    test_manifest_processed_processed=test_manifest_processed_processed,\n",
    "    train_manifest_processed_processed=train_manifest_processed_processed,\n",
    "    manifests_processed_all=manifests_processed_all\n",
    "))\n",
    "\n",
    "os.system(\"wc -l {manifests_processed_all}\".format(manifests_processed_all=manifests_processed_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_ngram_model(tokenizer, ngram_lm_path):\n",
    "    vocab_dict = tokenizer.get_vocab()\n",
    "    sort_vocab = sorted((value, key) for (key, value) in vocab_dict.items())\n",
    "    vocab = [x[1] for x in sort_vocab][:-2]\n",
    "    vocab_list = vocab\n",
    "    vocab_list[tokenizer.pad_token_id] = \"\"\n",
    "    vocab_list[tokenizer.unk_token_id] = \"\"\n",
    "    vocab_list[tokenizer.word_delimiter_token_id] = \" \"\n",
    "    alphabet = Alphabet.build_alphabet(vocab_list, ctc_token_idx=tokenizer.pad_token_id)\n",
    "    lm_model = kenlm.Model(ngram_lm_path)\n",
    "    decoder = BeamSearchDecoderCTC(alphabet, language_model=LanguageModel(lm_model))\n",
    "    return decoder\n",
    "\n",
    "wav2vec2_processor = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/wav2vec_models/preprocessor\"\n",
    "wav2vec2_model = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/wav2vec_models/CTCModel\"\n",
    "lm_file = \"/home/khoatlv/Conformer_ASR/scripts/evaluation/wav2vec_models/4-gram-lm_large.bin\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(wav2vec2_processor)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(wav2vec2_model).to(torch.device('cuda'))\n",
    "ngram_lm_model = get_decoder_ngram_model(processor.tokenizer, lm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manifest(path):\n",
    "    manifest = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"Reading manifest data\"):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            data = json.loads(line)\n",
    "            manifest.append(data)\n",
    "    return manifest\n",
    "\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = sf.read(batch[\"path\"])\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    return batch\n",
    "\n",
    "def read_wav(data_manifest):\n",
    "    try:\n",
    "        data = dict()\n",
    "        y, rate = sf.read(data_manifest[\"audio_filepath\"])\n",
    "        data[\"speed\"] = y\n",
    "        data[\"text\"] = data_manifest[\"text\"]\n",
    "        data[\"audio_filepath\"] = data_manifest[\"audio_filepath\"]\n",
    "        return data\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def read_batch(paths):\n",
    "    with Parallel(n_jobs=16, verbose=10) as parallel:\n",
    "        result = parallel(joblib.delayed(read_wav)(manifests_data) for manifests_data in paths)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def transcribe_ASR(raw_signal):\n",
    "    signal = np.asarray(raw_signal, dtype=np.float32).flatten()\n",
    "    input_values = processor(\n",
    "        signal,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_values.to(\"cuda\")\n",
    "    logits = model(input_values).logits[0]\n",
    "    # pred_ids = torch.argmax(logits, dim=-1)\n",
    "    # greedy_search_output = processor.decode(pred_ids)\n",
    "    beam_search_output = ngram_lm_model.decode(logits.cpu().detach().numpy(), beam_width=200)\n",
    "    return beam_search_output\n",
    "\n",
    "def save_log(log_data):\n",
    "    fieldnames = ['audio_filepath', 'text', 'pred', 'wer']\n",
    "    datas = [\n",
    "        [\n",
    "            data[\"audio_filepath\"], \n",
    "            data[\"text\"], \n",
    "            data[\"pred\"], \n",
    "            data[\"wer\"], \n",
    "        ] for data in log_data\n",
    "    ]\n",
    "\n",
    "    if os.path.exists(log_data_path):\n",
    "        print(\"old\")\n",
    "        with open(log_data_path, 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(datas)\n",
    "            f.close()\n",
    "    else:\n",
    "        print(\"new\")\n",
    "        with open(log_data_path, 'w', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(fieldnames)\n",
    "            writer.writerows(datas)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4707a25a0aec40dcba4ad30fbc713c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading manifest data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9141\n",
      "{'audio_filepath': '/home/khoatlv/data/data_collected/viettel/resample/mở-điều-hòa-ga-ra_2_0.wav', 'duration': 1.6138125, 'text': 'mở điều hòa ga ra'}\n"
     ]
    }
   ],
   "source": [
    "manifests_processed_all_data = read_manifest(manifests_processed_all)\n",
    "print(len(manifests_processed_all_data))\n",
    "print(manifests_processed_all_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Done  40 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.1735s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done  53 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Done  66 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Done  82 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0327s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done 112 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0312s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 152 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=16)]: Done 216 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0559s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 312 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=16)]: Done 464 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.1164s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 736 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=16)]: Done 802 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=16)]: Done 825 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=16)]: Done 848 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=16)]: Done 873 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=16)]: Done 898 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=16)]: Done 925 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=16)]: Done 952 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "Process 1000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0179s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0170s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0237s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 110 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0471s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0921s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 2000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0136s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0327s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0223s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 104 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0353s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 228 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0820s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 3000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0196s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0344s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0436s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 104 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0703s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.1151s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 4000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0152s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0319s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0236s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 106 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0568s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0956s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 5000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0114s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0171s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0345s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 104 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0498s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0837s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 6000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0121s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0191s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0269s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 104 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0595s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0625s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 520 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 7000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0138s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0171s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0223s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 106 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0535s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.1009s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 8000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0146s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0356s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0418s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done 104 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 164 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 224 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0536s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0827s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=16)]: Done 512 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "Process 9000 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0085s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0376s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  73 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  98 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 125 out of 141 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 141 out of 141 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "dataset_src = \"data_collected\"\n",
    "log_data_path = os.path.join(f\"/home/khoatlv/Conformer_ASR/scripts/evaluation/eval_data/{dataset_src}\", \"data_log.csv\")\n",
    "log_error_files_path = os.path.join(f\"/home/khoatlv/Conformer_ASR/scripts/evaluation/eval_data/{dataset_src}\", \"log_error_files.csv\")\n",
    "log_data = []\n",
    "error_files = []\n",
    "\n",
    "len_test = len(manifests_processed_all_data)\n",
    "# len_test = 5\n",
    "step = 1000\n",
    "create_file = True\n",
    "if os.path.exists(log_data_path): os.remove(log_data_path)\n",
    "if os.path.exists(log_error_files_path): os.remove(log_error_files_path)\n",
    "\n",
    "for i in range(0, len_test, step):\n",
    "    print(\"Process {} files\".format(i))\n",
    "    batch_data = []\n",
    "    if i + step >= len_test:\n",
    "        batch_data = read_batch(manifests_processed_all_data[i: len_test])\n",
    "    else:\n",
    "        batch_data = read_batch(manifests_processed_all_data[i: i + step])\n",
    "\n",
    "    for data in batch_data:\n",
    "        try:\n",
    "            log = dict()\n",
    "            log[\"audio_filepath\"] = data[\"audio_filepath\"]\n",
    "            log[\"text\"] = data[\"text\"]\n",
    "            log[\"wer\"] = None\n",
    "            log[\"pred\"] = None\n",
    "\n",
    "            if data is not None:\n",
    "                try:\n",
    "                    pred = transcribe_ASR(data[\"speed\"])\n",
    "                    wer_score = wer([pred], [data[\"text\"]])\n",
    "                    log[\"wer\"] = wer_score\n",
    "                    log[\"pred\"] = pred\n",
    "                    log_data.append(log)\n",
    "                except:\n",
    "                    error_files.append(data[\"audio_filepath\"])\n",
    "                    print(\"Error in file {}\".format(data))\n",
    "\n",
    "            if len(log_data) >= 1000:\n",
    "                save_log(log_data)\n",
    "                log_data = []\n",
    "        except Exception as e:\n",
    "            print(f\"{e}: {data}\")\n",
    "\n",
    "if len(log_data) > 0:\n",
    "    save_log(log_data)\n",
    "\n",
    "with open(log_error_files_path, 'w', encoding='UTF8', newline='') as f:\n",
    "    datas = \"\\n\".join(error_files)\n",
    "    f.writelines(datas)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
